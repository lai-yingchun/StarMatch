{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Overview\n",
        "===\n",
        "\n",
        "- 目標\n",
        "    - 利用Contrastive Representation Learning 訓練 Encoder，將品牌與名人向量映射至同一語意空間，找到適合品牌的代言人\n",
        "- 模型特徵\n",
        "    - 品牌描述向量 (以LLM生成品牌描述，再透過 Voyage AI 的embedding model 將品牌描述轉換為向量): 1024 dimensions\n",
        "    - 品牌 brand personality （Jennifer Aaker 品牌人格五大構面）\n",
        "    - 品牌類別: 13 dimensions\n",
        "    - 代言人性別: 1 dimension\n",
        "    - 代言人年齡區間: 8 dimensions\n",
        "    - 代言人人格特質向量  (以LLM生成代言人人格特質描述，再透過 Voyage AI 的embedding model 將代言人的人格特質描述轉換為向量): 1024 dimensions\n",
        "- 模型評估\n",
        "    - 對於測試集中的每個品牌，模型會輸出預測的名人向量\n",
        "    - 計算該預測向量與所有候選名人向量的 cosine similarity\n",
        "    - 選擇最相似(前10)的名人，作為「預測名人」\n",
        "      - 如果這個(前10)名人確實跟該品牌有代言關係，則視為正確\n",
        "    - 最後計算Top-1 Accuracy, Top-10 Accuracy"
      ],
      "metadata": {
        "id": "Lqu4VxbVEg77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare data for modeling"
      ],
      "metadata": {
        "id": "mxkM657D_o9i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RhEft9s21AtS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# train test split\n",
        "train_df, test_df = train_test_split(df_joined, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = train_df[brand_cols + demo_col + product_cat].to_numpy().astype(np.float32) # 1046 dimensions\n",
        "y_train = train_df[celeb_cols].to_numpy().astype(np.float32) # 1024 dimensions\n",
        "\n",
        "X_test = test_df[brand_cols + demo_col + product_cat].to_numpy().astype(np.float32) # 1046 dimensions\n",
        "y_test = test_df[celeb_cols].to_numpy().astype(np.float32) # 1024 dimensions\n",
        "test_celeb_ids = test_df[celeb_id_col].to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define loss, model architecture, evaluation metrics"
      ],
      "metadata": {
        "id": "V1qX7ls3_R-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers, regularizers\n",
        "\n",
        "\n",
        "def build_brand_encoder(input_dim, embed_dim=128):\n",
        "    inputs = layers.Input(shape=(input_dim,))\n",
        "    x = layers.Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(5e-4))(inputs)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(embed_dim)(x)\n",
        "    outputs = layers.Lambda(lambda t: tf.nn.l2_normalize(t, axis=-1))(outputs)\n",
        "    return models.Model(inputs, outputs, name=\"brand_encoder\")\n",
        "\n",
        "\n",
        "def triplet_loss(margin=0.2):\n",
        "    def loss_fn(y_true, y_pred):\n",
        "        embed_dim = tf.shape(y_pred)[1] // 3\n",
        "        anchor = y_pred[:, 0:embed_dim]\n",
        "        positive = y_pred[:, embed_dim:2*embed_dim]\n",
        "        negative = y_pred[:, 2*embed_dim:3*embed_dim]\n",
        "\n",
        "        # cosine similarity\n",
        "        def cos_sim(x, y):\n",
        "            x = tf.nn.l2_normalize(x, axis=-1)\n",
        "            y = tf.nn.l2_normalize(y, axis=-1)\n",
        "            return tf.reduce_sum(x * y, axis=-1)\n",
        "\n",
        "        pos_sim = cos_sim(anchor, positive)\n",
        "        neg_sim = cos_sim(anchor, negative)\n",
        "\n",
        "        losses = tf.maximum(0.0, neg_sim - pos_sim + margin)\n",
        "        return tf.reduce_mean(losses)\n",
        "    return loss_fn\n",
        "\n",
        "\n",
        "def build_triplet_model(input_dim=27, celeb_dim=1024, embed_dim=128):\n",
        "    brand_encoder = build_brand_encoder(input_dim, embed_dim)\n",
        "\n",
        "    # input\n",
        "    brand_in = layers.Input(shape=(input_dim,))\n",
        "    celeb_pos_in = layers.Input(shape=(celeb_dim,))\n",
        "    celeb_neg_in = layers.Input(shape=(celeb_dim,))\n",
        "\n",
        "    # brand → embedding\n",
        "    anchor = brand_encoder(brand_in)\n",
        "\n",
        "    # encode celeb to the same dimensions\n",
        "    celeb_proj = models.Sequential([\n",
        "        layers.Dense(embed_dim),\n",
        "        layers.Lambda(lambda t: tf.nn.l2_normalize(t, axis=-1))\n",
        "    ])\n",
        "    positive = celeb_proj(celeb_pos_in)\n",
        "    negative = celeb_proj(celeb_neg_in)\n",
        "\n",
        "\n",
        "    merged = layers.Concatenate(axis=-1)([anchor, positive, negative])\n",
        "\n",
        "    model = models.Model([brand_in, celeb_pos_in, celeb_neg_in], merged)\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_triplets(X, y, celeb_ids, num_triplets=10000):\n",
        "    triplets = []\n",
        "    n = len(X)\n",
        "    for _ in range(num_triplets):\n",
        "        i = np.random.randint(0, n)  # index of anchor and positive sample\n",
        "        while True:\n",
        "            k = np.random.randint(0, n)  # index of negative sample (randomly choose a negative sample)\n",
        "            if celeb_ids[k] != celeb_ids[i]:  # negative sample should be different from positive sample\n",
        "                break\n",
        "        triplets.append((X[i], y[i], y[k]))\n",
        "\n",
        "    brand_arr = np.array([t[0] for t in triplets]) # anchor\n",
        "    pos_arr = np.array([t[1] for t in triplets])\n",
        "    neg_arr = np.array([t[2] for t in triplets])\n",
        "    return [brand_arr, pos_arr, neg_arr]\n",
        "\n",
        "\n",
        "def evaluate_topk_triplet(brand_encoder, celeb_proj, X_test, y_test, celeb_ids, df, K=10, detail=False):\n",
        "\n",
        "  # Encode\n",
        "  brand_embeds = brand_encoder.predict(X_test, verbose=0)\n",
        "  celeb_embeds = celeb_proj.predict(y_test, verbose=0)\n",
        "\n",
        "  brand_embeds /= np.linalg.norm(brand_embeds, axis=1, keepdims=True)\n",
        "  celeb_embeds /= np.linalg.norm(celeb_embeds, axis=1, keepdims=True)\n",
        "\n",
        "  top1, topk = 0, 0\n",
        "  n = len(X_test)\n",
        "\n",
        "  for i in range(n):\n",
        "      sims = np.dot(celeb_embeds, brand_embeds[i])  # for every brand, find the cosine similarities of the brand and all the celebrities\n",
        "      sorted_idx = np.argsort(sims)[::-1]\n",
        "\n",
        "      # find the top 10 most similar celebrities of the brand\n",
        "      ranked_ids = []\n",
        "      for idx in sorted_idx:\n",
        "          cid = celeb_ids[idx]\n",
        "          if cid not in ranked_ids:\n",
        "              ranked_ids.append(cid)\n",
        "          if len(ranked_ids) >= K:\n",
        "              break\n",
        "      # Top-1\n",
        "      if ranked_ids[0] == celeb_ids[i]:\n",
        "          top1 += 1\n",
        "      # Top-10\n",
        "      if celeb_ids[i] in ranked_ids:\n",
        "          topk += 1\n",
        "\n",
        "  return top1 / n, topk / n\n"
      ],
      "metadata": {
        "id": "SOc8EuSw2vG2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "GDQLmBRA_KXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_triplets = create_triplets(X_train, y_train, train_df[celeb_id_col].to_numpy(), num_triplets=20000)\n",
        "\n",
        "\n",
        "model = build_triplet_model(input_dim=X_train.shape[1], celeb_dim=y_train.shape[1], embed_dim=128)\n",
        "model.compile(optimizer=optimizers.Adam(1e-4), loss=triplet_loss(margin=0.2))\n",
        "\n",
        "history = model.fit(\n",
        "    train_triplets, np.zeros(len(train_triplets[0])),\n",
        "    batch_size=64,\n",
        "    epochs=20,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze5OLCOs24dU",
        "outputId": "8f654afe-dc77-4f92-de91-d772f60e12ad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.1815\n",
            "Epoch 2/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0933\n",
            "Epoch 3/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0675\n",
            "Epoch 4/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0546\n",
            "Epoch 5/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.0477\n",
            "Epoch 6/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0411\n",
            "Epoch 7/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0372\n",
            "Epoch 8/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0334\n",
            "Epoch 9/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0325\n",
            "Epoch 10/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0296\n",
            "Epoch 11/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0276\n",
            "Epoch 12/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0271\n",
            "Epoch 13/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0253\n",
            "Epoch 14/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0251\n",
            "Epoch 15/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0235\n",
            "Epoch 16/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0226\n",
            "Epoch 17/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0219\n",
            "Epoch 18/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0213\n",
            "Epoch 19/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0200\n",
            "Epoch 20/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "LwIGtkg4_OCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the encoders from model\n",
        "brand_encoder = model.get_layer(\"brand_encoder\")\n",
        "celeb_proj = model.get_layer(index=-2)\n",
        "\n",
        "# evaluate performance with test dataset\n",
        "top1_acc, top10_acc = evaluate_topk_triplet(brand_encoder, celeb_proj, X_test, y_test, test_celeb_ids,test_df, K=10)\n",
        "print(f\"Evaluation with test dataset: Top-1 Accuracy: {top1_acc:.4f}\")\n",
        "print(f\"Evaluation with test dataset: Top-10 Accuracy: {top10_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd7kpOoa3BJi",
        "outputId": "030a7f1f-0b4e-4339-8145-bb61510c80ff"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation with test dataset: Top-1 Accuracy: 0.1462\n",
            "Evaluation with test dataset: Top-10 Accuracy: 0.6923\n"
          ]
        }
      ]
    }
  ]
}